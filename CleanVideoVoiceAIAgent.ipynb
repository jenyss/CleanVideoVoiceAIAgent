{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "378d2adc-e032-4a4c-808d-71fe560b40b3",
   "metadata": {},
   "source": [
    "<h1>Video Voice Clean-Up AI Agent</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaefdff-4873-4539-acc4-5635b44dc356",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langgraph openai ffmpeg-python requests python-dotenv demucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e1909b-ff15-493a-acfa-f7eb48059c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from langchain.tools import Tool\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from openai import OpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv()\n",
    "ELEVENLABS_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")  # Set your ElevenLabs API key in the .env file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f8f35a-4ec5-471f-8e97-687e81346faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the schema\n",
    "class ExtractAudioSchema(BaseModel):\n",
    "    video_path: str\n",
    "    output_audio_path: str\n",
    "\n",
    "\n",
    "\n",
    "def extract_audio(video_path: str, output_audio_path: str = None) -> str:\n",
    "    \"\"\"Extracts audio from a video file using FFmpeg.\"\"\"\n",
    "    \n",
    "    # If output_audio_path is not provided, generate a default name\n",
    "    if output_audio_path is None:\n",
    "        base_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "        output_audio_path = os.path.join(\"downloads\", f\"{base_name}_audio.wav\")\n",
    "\n",
    "    print(f\"Extracting audio from {video_path} to {output_audio_path}\")\n",
    "\n",
    "    subprocess.run([\"ffmpeg\", \"-i\", video_path, \"-q:a\", \"0\", \"-map\", \"a\", output_audio_path], check=True)\n",
    "    \n",
    "    if not os.path.exists(output_audio_path):\n",
    "        raise FileNotFoundError(f\"Audio extraction failed: {output_audio_path} was not created.\")\n",
    "\n",
    "    return output_audio_path\n",
    "    \n",
    "\n",
    "extract_audio_tool = StructuredTool(\n",
    "    name=\"ExtractAudio\",\n",
    "    func=extract_audio,\n",
    "    description=\"Extracts audio from a video file using FFmpeg. Requires video_path and output_audio_path arguments.\",\n",
    "    args_schema=ExtractAudioSchema\n",
    ")\n",
    "\n",
    "# Using requests at first but then switching to OpenAI API directly - see uncommented tool definition below.\n",
    "# Transcribe Audio Tool using OpenAI Whisper API\n",
    "# File Size Limit: 25 MB (for a single request)\n",
    "# Duration Limit: ~30 minutes (varies depending on bitrate and file compression)\n",
    "# If your audio file exceeds 25 MB, youâ€™ll need to chunk it into smaller segments before processing!\n",
    "# def transcribe_audio(audio_path):\n",
    "#     \"\"\"Transcribes audio using OpenAI Whisper API.\"\"\"\n",
    "#     with open(audio_path, \"rb\") as audio_file:\n",
    "#         result = requests.post(\n",
    "#             \"https://api.openai.com/v1/audio/transcriptions\",\n",
    "#             headers={\"Authorization\": f\"Bearer {os.getenv('OPENAI_API_KEY')}\"},\n",
    "#             files={\"file\": audio_file},\n",
    "#             data={\"model\": \"whisper-1\"}\n",
    "#         )\n",
    "#         result.raise_for_status()\n",
    "#         transcript = result.json()[\"text\"]\n",
    "\n",
    "#     # Save the transcript to a file\n",
    "#     transcript_path = audio_path.replace(\".wav\", \".txt\")\n",
    "#     with open(transcript_path, \"w\") as file:\n",
    "#         file.write(transcript)\n",
    "\n",
    "#     return transcript_path\n",
    "\n",
    "# transcribe_audio_tool = Tool(\n",
    "#     name=\"TranscribeAudio\",\n",
    "#     func=transcribe_audio,\n",
    "#     description=\"Transcribes an audio file into text using OpenAI Whisper API.\"\n",
    "# )\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"Transcribes audio using OpenAI Whisper API.\"\"\"\n",
    "    client = OpenAI()\n",
    "    \n",
    "    with open(audio_path, \"rb\") as audio_file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\", \n",
    "            file=audio_file\n",
    "        )\n",
    "    \n",
    "    transcript_text = transcription.text\n",
    "    \n",
    "    # Save the transcript to a file\n",
    "    transcript_path = audio_path.replace(\".wav\", \".txt\")\n",
    "    with open(transcript_path, \"w\") as file:\n",
    "        file.write(transcript_text)\n",
    "    \n",
    "    return transcript_path\n",
    "\n",
    "transcribe_audio_tool = Tool(\n",
    "    name=\"TranscribeAudio\",\n",
    "    func=transcribe_audio,\n",
    "    description=\"Transcribes an audio file into text using OpenAI Whisper API.\"\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "def clean_transcript(transcript_path):\n",
    "    \"\"\"Uses GPT-4o to clean and enhance the transcript.\"\"\"\n",
    "    \n",
    "    with open(transcript_path, \"r\") as file:\n",
    "        transcript = file.read()\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Clean up this transcript: {transcript}\n",
    "    \n",
    "    - Remove filler words\n",
    "    - Improve readability\n",
    "    - Preserve meaning and context\n",
    "    - Return only the cleaned transcript as plain text\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    try:\n",
    "        cleaned_text = response.content.strip()\n",
    "\n",
    "        cleaned_path = transcript_path.replace(\".txt\", \"_cleaned.txt\")\n",
    "        with open(cleaned_path, \"w\") as file:\n",
    "            file.write(cleaned_text)\n",
    "\n",
    "        return cleaned_path\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to clean transcript: {response.content}. Error: {e}\")\n",
    "\n",
    "clean_transcript_tool = Tool(\n",
    "    name=\"CleanTranscript\",\n",
    "    func=clean_transcript,\n",
    "    description=\"Cleans up a transcript using GPT-4o to remove filler words and improve readability.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Define ElevenLabs Voice Generation\n",
    "def generate_ai_voice_elevenlabs(cleaned_transcript_path, output_audio_path=None):\n",
    "    \"\"\"Generates an AI voice from the cleaned transcript using ElevenLabs.\"\"\"\n",
    "    ELEVENLABS_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")  # Load API key from env\n",
    "\n",
    "    if not ELEVENLABS_API_KEY:\n",
    "        raise ValueError(\"ElevenLabs API key is missing. Set it in the .env file.\")\n",
    "\n",
    "    # Ensure the output path is set and within the downloads directory\n",
    "    if output_audio_path is None:\n",
    "        filename = os.path.basename(cleaned_transcript_path).replace(\"_cleaned.txt\", \"_ai.wav\")\n",
    "        output_audio_path = os.path.join(\"downloads\", filename)\n",
    "\n",
    "    # Read the cleaned transcript\n",
    "    with open(cleaned_transcript_path, \"r\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # ElevenLabs API settings\n",
    "    url = \"https://api.elevenlabs.io/v1/text-to-speech\"\n",
    "    # voice_id = \"pMsXgVXv3BLzUgSXRplE\"  # EventLabs voice ID (woman), cannot remember which one exactly.\n",
    "    voice_id = \"!!!!!!!!!!!!!!!!!!!!!REMOVED SINCE IT WAS MY VOICE, USE THE ONE ABOVE OR CLONE YOURS!!!!!!!!!!!!!!!!!!!!\" # JENYS\n",
    "\n",
    "    headers = {\n",
    "        \"xi-api-key\": ELEVENLABS_API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"text\": text,\n",
    "        \"voice_settings\": {\n",
    "            \"stability\": 0.7,  # Adjust for consistency in speech\n",
    "            \"similarity_boost\": 0.9  # Boosts similarity to training data\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Make the API request\n",
    "    response = requests.post(f\"{url}/{voice_id}\", headers=headers, json=payload)\n",
    "    response.raise_for_status()  # Raise error if request fails\n",
    "\n",
    "    # Save the generated audio\n",
    "    with open(output_audio_path, \"wb\") as audio_file:\n",
    "        audio_file.write(response.content)\n",
    "\n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "# AI Voice Tool\n",
    "class GenerateAIVoiceSchema(BaseModel):\n",
    "    cleaned_transcript_path: str\n",
    "    output_audio_path: str = \"downloads/generated_voice_ai.wav\"\n",
    "\n",
    "ai_voice_tool = StructuredTool(\n",
    "    name=\"GenerateAIVoice\",\n",
    "    func=generate_ai_voice_elevenlabs,\n",
    "    description=\"Generates AI voice from cleaned transcript using ElevenLabs.\",\n",
    "    args_schema=GenerateAIVoiceSchema\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_old_voice(video_path: str, output_video_path: str = None) -> str:\n",
    "    \"\"\"Removes all audio from the original video using FFmpeg.\"\"\"\n",
    "    \n",
    "    # Ensure the function does not create endless `_cleaned.mov` files\n",
    "    if \"_cleaned\" in video_path:\n",
    "        print(f\"âš ï¸ Skipping already cleaned video: {video_path}\")\n",
    "        return video_path  # Return the same path if it's already cleaned\n",
    "\n",
    "    if output_video_path is None:\n",
    "        base_name = os.path.splitext(video_path)[0]\n",
    "        output_video_path = f\"{base_name}_cleaned.mov\"\n",
    "\n",
    "    print(f\"ðŸ§¹ Removing all audio from {video_path} -> {output_video_path}\")\n",
    "\n",
    "    # FFmpeg command to remove all audio\n",
    "    result = subprocess.run([\n",
    "        \"ffmpeg\", \"-i\", video_path, \"-c:v\", \"copy\", \"-an\", \"-y\", output_video_path\n",
    "    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"âŒ FFmpeg error while removing audio: {result.stderr}\")\n",
    "        return None\n",
    "\n",
    "    if not os.path.exists(output_video_path):\n",
    "        print(f\"âŒ Error: Cleaned video {output_video_path} was not created.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"âœ… Successfully created cleaned video: {output_video_path}\")\n",
    "    return output_video_path\n",
    "\n",
    "\n",
    "# Register the tool in LangGraph\n",
    "remove_old_voice_tool = Tool(\n",
    "    name=\"RemoveOldVoice\",\n",
    "    func=remove_old_voice,\n",
    "    description=\"Removes all audio from a video file using FFmpeg, creating a silent version.\"\n",
    ")\n",
    "\n",
    "# Used by the merge_audio_with_adjustment Tool\n",
    "def adjust_voice_timing(original_audio: str, ai_audio: str, adjusted_ai_audio: str):\n",
    "    \"\"\"Synchronizes the AI-generated voice duration with the original extracted audio.\"\"\"\n",
    "    \n",
    "    def get_audio_duration(audio_file):\n",
    "        if not os.path.exists(audio_file):\n",
    "            print(f\"âŒ Error: {audio_file} does not exist.\")\n",
    "            return None\n",
    "        \n",
    "        result = subprocess.run(\n",
    "            [\"ffprobe\", \"-i\", audio_file, \"-show_entries\", \"format=duration\", \"-v\", \"quiet\", \"-of\", \"csv=p=0\"],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "\n",
    "        if result.returncode != 0:\n",
    "            print(f\"âŒ FFprobe error for {audio_file}: {result.stderr}\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            return float(result.stdout.strip())\n",
    "        except ValueError:\n",
    "            print(f\"âŒ Error: Could not parse duration from {audio_file}\")\n",
    "            return None\n",
    "\n",
    "    print(f\"ðŸ” Checking durations for: {original_audio} (original) and {ai_audio} (AI-generated)\")\n",
    "\n",
    "    original_duration = get_audio_duration(original_audio)\n",
    "    ai_duration = get_audio_duration(ai_audio)\n",
    "\n",
    "    if original_duration is None or ai_duration is None:\n",
    "        print(\"âŒ Error: Could not retrieve audio durations.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"ðŸ•’ Original Duration: {original_duration:.2f} sec, AI Duration: {ai_duration:.2f} sec\")\n",
    "\n",
    "    # Correct speed factor to match original duration\n",
    "    speed_factor = ai_duration / original_duration if original_duration > 0 else 1.0\n",
    "\n",
    "    if not (0.5 <= speed_factor <= 2.0):\n",
    "        print(f\"âš ï¸ Warning: Speed factor {speed_factor:.2f} is out of range. Clamping.\")\n",
    "        speed_factor = max(0.5, min(speed_factor, 2.0))\n",
    "\n",
    "    print(f\"ðŸŽµ Applying time-stretching adjustment with atempo={speed_factor:.3f}\")\n",
    "\n",
    "    # Ensure adjusted file doesn't exist before processing\n",
    "    if os.path.exists(adjusted_ai_audio):\n",
    "        print(f\"ðŸ—‘ï¸ Deleting existing adjusted audio file: {adjusted_ai_audio}\")\n",
    "        os.remove(adjusted_ai_audio)\n",
    "\n",
    "    # Apply time-stretching with correct speed factor\n",
    "    result = subprocess.run([\n",
    "        \"ffmpeg\", \"-i\", ai_audio, \"-filter:a\", f\"atempo={speed_factor:.3f}\", \n",
    "        \"-y\", adjusted_ai_audio\n",
    "    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"âŒ FFmpeg error while adjusting voice timing: {result.stderr}\")\n",
    "        return None\n",
    "\n",
    "    if not os.path.exists(adjusted_ai_audio):\n",
    "        print(f\"âŒ Error: Adjusted audio file {adjusted_ai_audio} was not created.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"âœ… Successfully created adjusted audio: {adjusted_ai_audio}\")\n",
    "    return adjusted_ai_audio\n",
    "\n",
    "\n",
    "# def merge_audio_with_adjustment(video_path: str, new_voice_path: str, output_video_path: str = None):\n",
    "#     \"\"\"Merges new AI-generated voice into the cleaned original video using FFmpeg.\"\"\"\n",
    "\n",
    "#     # If the user already passed a file ending in \"_cleaned.mov\",\n",
    "#     # use that directly as the cleaned video; otherwise append \"_cleaned\".\n",
    "#     if video_path.endswith(\"_cleaned.mov\"):\n",
    "#         cleaned_video_path = video_path\n",
    "#         # Remove just the \"_cleaned\" portion from base_name so we pick up the correct\n",
    "#         # original extracted audio name (e.g. myvideo_audio.wav, not myvideo_cleaned_audio.wav).\n",
    "#         base_name = os.path.splitext(video_path)[0].replace(\"_cleaned\", \"\")\n",
    "#     else:\n",
    "#         base_name = os.path.splitext(video_path)[0]\n",
    "#         cleaned_video_path = f\"{base_name}_cleaned.mov\"\n",
    "\n",
    "#     extracted_audio_path = f\"{base_name}_audio.wav\"\n",
    "\n",
    "#     if not os.path.exists(cleaned_video_path):\n",
    "#         print(f\"âŒ Error: Cleaned video file {cleaned_video_path} does not exist.\")\n",
    "#         return None\n",
    "\n",
    "#     if not os.path.exists(extracted_audio_path):\n",
    "#         print(f\"âŒ Error: Extracted audio file {extracted_audio_path} does not exist.\")\n",
    "#         return None\n",
    "\n",
    "#     # Adjust AI-generated voice timing before merging\n",
    "#     adjusted_voice_path = os.path.splitext(new_voice_path)[0] + \"_adjusted.wav\"\n",
    "#     adjusted_voice_path = adjust_voice_timing(extracted_audio_path, new_voice_path, adjusted_voice_path)\n",
    "#     if adjusted_voice_path is None:\n",
    "#         print(\"âŒ Error: Adjusted voice file was not created. Merging process aborted.\")\n",
    "#         return None\n",
    "\n",
    "#     if output_video_path is None:\n",
    "#         output_video_path = f\"{base_name}_final.mov\"\n",
    "\n",
    "#     print(f\"ðŸŽ¬ Merging cleaned video: {cleaned_video_path} with adjusted voice: {adjusted_voice_path}\")\n",
    "\n",
    "#     # FFmpeg command: Replace the cleaned video audio track with the adjusted AI-generated voice\n",
    "#     result = subprocess.run([\n",
    "#         \"ffmpeg\", \"-i\", cleaned_video_path, \"-i\", adjusted_voice_path,\n",
    "#         \"-c:v\", \"copy\", \"-c:a\", \"aac\", \"-map\", \"0:v:0\", \"-map\", \"1:a:0\",\n",
    "#         \"-movflags\", \"faststart\",\n",
    "#         \"-y\", output_video_path\n",
    "#     ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "#     if result.returncode != 0:\n",
    "#         print(f\"âŒ FFmpeg error while merging audio and video: {result.stderr}\")\n",
    "#         return None\n",
    "\n",
    "#     print(f\"âœ… Successfully created final video: {output_video_path}\")\n",
    "#     return output_video_path\n",
    "\n",
    "\n",
    "# Merge AI Voice into the Original Video (.mov format). !!!DOES NOT SUPPORT ADJUSTED TIMING!!!\n",
    "def merge_audio_no_adjustment(video_path: str, new_voice_path: str, output_video_path: str = None):\n",
    "    \"\"\"\n",
    "    Merges the new AI-generated voice into a cleaned version of the video,\n",
    "    WITHOUT applying any timing adjustments to the AI voice.\n",
    "    If the passed video_path does not end with \"_cleaned.mov\", it appends \"_cleaned.mov\".\n",
    "    \"\"\"\n",
    "\n",
    "    # If user passes e.g. \"myvideo_cleaned.mov\", use that directly.\n",
    "    # Otherwise, assume the cleaned version is \"myvideo_cleaned.mov\".\n",
    "    if video_path.endswith(\"_cleaned.mov\"):\n",
    "        cleaned_video_path = video_path\n",
    "        # Remove \"_cleaned\" to get the base for naming final output if needed\n",
    "        base_name = os.path.splitext(video_path)[0].replace(\"_cleaned\", \"\")\n",
    "    else:\n",
    "        base_name = os.path.splitext(video_path)[0]\n",
    "        cleaned_video_path = f\"{base_name}_cleaned.mov\"\n",
    "\n",
    "    # Ensure the cleaned video exists\n",
    "    if not os.path.exists(cleaned_video_path):\n",
    "        print(f\"âŒ Error: Cleaned video file {cleaned_video_path} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    # If user didn't supply output, create it as \"myvideo_final.mov\" or similar\n",
    "    if output_video_path is None:\n",
    "        output_video_path = f\"{base_name}_final.mov\"\n",
    "\n",
    "    print(f\"ðŸŽ¬ Merging (no timing adjust) video: {cleaned_video_path} + AI voice: {new_voice_path}\")\n",
    "\n",
    "    # FFmpeg command: Replace the cleaned video audio track with the AI-generated voice\n",
    "    result = subprocess.run([\n",
    "        \"ffmpeg\", \"-i\", cleaned_video_path, \"-i\", new_voice_path,\n",
    "        \"-c:v\", \"copy\", \"-c:a\", \"aac\",\n",
    "        \"-map\", \"0:v:0\", \"-map\", \"1:a:0\",\n",
    "        \"-movflags\", \"faststart\", \"-y\", output_video_path\n",
    "    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"âŒ FFmpeg error while merging audio and video: {result.stderr}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"âœ… Successfully created final video (no timing adjust): {output_video_path}\")\n",
    "    return output_video_path\n",
    "\n",
    "\n",
    "# Registering MergeAudio as a StructuredTool\n",
    "class MergeAudioSchema(BaseModel):\n",
    "    video_path: str\n",
    "    new_voice_path: str\n",
    "    output_video_path: str = None  # Optional parameter\n",
    "\n",
    "merge_audio_tool = StructuredTool(\n",
    "    name=\"MergeAudio\",\n",
    "    # func=merge_audio_with_adjustment, #!!! If you want to use adjustment, slower or faster voice pace, then uncomment this line and the respective function above AND comment next line!\n",
    "    func=merge_audio_no_adjustment,\n",
    "    description=\"Merges the new AI-generated voice into the original .mov video using FFmpeg.\",\n",
    "    args_schema=MergeAudioSchema\n",
    ")\n",
    "\n",
    "\n",
    "# Tools for LangGraph\n",
    "tools = [\n",
    "    extract_audio_tool,\n",
    "    transcribe_audio_tool,\n",
    "    clean_transcript_tool,\n",
    "    ai_voice_tool,\n",
    "    remove_old_voice_tool,\n",
    "    merge_audio_tool\n",
    "]\n",
    "\n",
    "# System Prompt for LangGraph\n",
    "system_prompt = \"\"\"You are an AI assistant that processes videos by replacing their original voice with an AI-generated voice. \n",
    "Your workflow includes: \n",
    "extracting audio from the video, \n",
    "transcribing it, \n",
    "cleaning the transcript to remove filler words, \n",
    "generating a new AI voice from the cleaned text, \n",
    "and merging it back into the video while removing the old voice. \n",
    "Ensure high accuracy and natural-sounding output.\"\"\"\n",
    "\n",
    "\n",
    "# Create LangGraph Agent\n",
    "graph = create_react_agent(\n",
    "    model=ChatOpenAI(model=\"gpt-4o\"),\n",
    "    tools=tools,\n",
    "    prompt=system_prompt,\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "# Process Video Function\n",
    "def process_video(video_path):\n",
    "    \"\"\"Runs the complete AI workflow for voice replacement.\"\"\"\n",
    "    inputs = {\"messages\": [(\"user\", f\"Help me clean my {video_path} video and get one with clean voice.\")]}\n",
    "    for step in graph.stream(inputs, stream_mode=\"steps\"):\n",
    "        message = step[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "# Example Usage\n",
    "process_video(\"downloads/test_recording.mov\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3984386-8bf6-4375-99fa-2c4f563d207d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
